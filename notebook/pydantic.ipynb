{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydantic is all you need: Jason Liu\n",
    "\n",
    "https://www.youtube.com/watch?v=yj-wSRJwrrc&list=WL&index=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Introduction to Structured Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step1: Import and Patch the Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter..\n",
    "import os\n",
    "import instructor\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "client = instructor.patch(OpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our instructor.patch for the OpenAI class introduces three key enhancements:\n",
    "\n",
    "- Response Mode: Specify a Pydantic model to streamline data extraction.\n",
    "- Max Retries: Set your desired number of retry attempts for requests.\n",
    "- Validation Context: Provide a context object for enhanced validator access. A Glimpse into Instructor's Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Define the Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model to define the structure of the data you want to extract.\n",
    "# This model will map directly to the information in the prompt.\n",
    "\n",
    "class ProductDetail(BaseModel):\n",
    "    collection: str\n",
    "    category: str\n",
    "    sales_last_month: float\n",
    "    inventory_count: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Extract Data with ChatCompletion\n",
    "\n",
    "- Use the client.chat.completions.create method to send a prompt and extract the data into the Pydantic object.\n",
    "- The response_model parameter specifies the Pydantic model to use for extraction.\n",
    "- Its helpful to annotate the variable with the type of the response model. which will help your IDE provide autocomplete and spell check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=ProductDetail,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Oviedo from coffee tables category are sold 15000 euros last month, the inventory was 40 units at the beginning of the month.\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user.collection == \"Oviedo\"\n",
    "assert user.category == \"coffee tables\"\n",
    "assert user.sales_last_month == 15000\n",
    "assert user.inventory_count == 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Validate the Extracted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 validation error for QuestionAnswer\n",
      "answer\n",
      "  Assertion failed, The statement promotes objectionable behavior. [type=assertion_error, input_value='The meaning of life is to be evil and steal', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.5/v/assertion_error\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, ValidationError, BeforeValidator\n",
    "from typing_extensions import Annotated\n",
    "from instructor import llm_validator\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: Annotated[\n",
    "        str,\n",
    "        BeforeValidator(llm_validator(\"don't say objectionable things\"))\n",
    "    ]\n",
    "\n",
    "try:\n",
    "    qa = QuestionAnswer(\n",
    "        question=\"What is the meaning of life?\",\n",
    "        answer=\"The meaning of life is to be evil and steal\",\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nothing special, just control flow\n",
    "\n",
    "- Handling missing data: Program with NLP instead of chaining\n",
    "\n",
    "- Reuse components: work time, leasure time. If not parsed correctly, add chain of thoughts\n",
    "\n",
    "- Add \"chain of thought\" to specific components\n",
    "\n",
    "- Extract arbitrary values\n",
    "\n",
    "- Extract Entities and relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Structured Prompting lets you define components**: Not only model represent the prompt, and the data, we can attach behaviors with methods\n",
    "\n",
    "- **Structured Prompting outputs data structures**: Represent knowledge, workflows, and plans that can be processed by downstream computer system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
